{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad63a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23.5\n",
      "2.0.0+cu117\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n",
    "\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import random\n",
    "import math\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1373976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23.5\n",
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from mini_avalam_5x5 import *\n",
    "from Self_Play_mini_avalam_5x5 import *\n",
    "from data_augmentation import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "board_size = 5*5 \n",
    "rows = 5\n",
    "columns = 5 \n",
    "## create dictionary to map actions from indices to action tuple type\n",
    "def create_action_dictionary():\n",
    "    action_dict = {}\n",
    "    index = 0\n",
    "    for row in range(rows):\n",
    "        for col in range(columns):\n",
    "            for drow in range(-1, 2):\n",
    "                for dcol in range(-1, 2):\n",
    "                    if drow == 0 and dcol == 0:\n",
    "                        continue\n",
    "                    new_row = row + drow\n",
    "                    new_col = col + dcol\n",
    "                    if 0 <= new_row < rows and 0 <= new_col < columns:\n",
    "                        action_dict[(row, col, new_row, new_col)] = index\n",
    "                        index += 1\n",
    "    return action_dict\n",
    "\n",
    "action_dict = create_action_dictionary()\n",
    "index_to_action = {index: action for action, index in action_dict.items()}\n",
    "\n",
    "initial_state = [     [ 0, -1,  1, -1,  0],  \n",
    "                      [ 0,  1, -1,  1, -1],  \n",
    "                      [ 1, -1,  1, -1,  1],  \n",
    "                      [-1,  1, -1,  1,  0],  \n",
    "                      [ 1, -1,  1, -1,  0] ] \n",
    "actions_size = len(action_dict) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b86a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_top_actions(top_actions, action_probs):\n",
    "    \"\"\"\n",
    "    Plot the top action probabilities from the MCTS search.\n",
    "\n",
    "    Args:\n",
    "        top_actions (list): A list of action indices representing the top actions.\n",
    "        action_probs (np.array): A numpy array containing the probabilities of each action.\n",
    "    \"\"\"\n",
    "    top_probabilities = [action_probs[action_index] for action_index in top_actions]\n",
    "\n",
    "    # Get the action coordinates from the action indices\n",
    "    top_action_coordinates = [index_to_action[action_index] for action_index in top_actions]\n",
    "\n",
    "    # Create the bar plot with top actions\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.bar(range(len(top_actions)), top_probabilities)\n",
    "    plt.xticks(range(len(top_actions)), top_action_coordinates, rotation=90)\n",
    "    plt.xlabel('Top Actions (from_x, from_y, to_x, to_y)')\n",
    "    plt.ylabel('Policy Probability')\n",
    "    plt.title('Top Policy Probabilities')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4d40286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def play_games(num_games, agent1, agent2, agent1_args=None, agent2_args=None):\n",
    "    agent1_wins = 0\n",
    "    agent2_wins = 0\n",
    "    draws = 0\n",
    "\n",
    "    for i in range(num_games):\n",
    "        if i % 2 == 0:\n",
    "            score = play_game(agent1, agent2, agent1_args, agent2_args, display=False)\n",
    "        else:\n",
    "            score = -play_game(agent2, agent1, agent2_args, agent1_args, display=False)\n",
    "\n",
    "        if score > 0:\n",
    "            agent1_wins += 1\n",
    "        elif score < 0:\n",
    "            agent2_wins += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "\n",
    "    return agent1_wins, agent2_wins, draws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823d66ed",
   "metadata": {},
   "source": [
    "### Load Model and check the action probabilites and value for a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbdc35c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.10985195636749268\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## state Encoding \n",
    "state =  np.array(       [[-1, -2,  1,  3,  0],  \n",
    "                          [ 1,  1,  3,  0,  0],  \n",
    "                          [ 0,  0,  0,  0,  1],  \n",
    "                          [ 0,  0, -3,  0,  0],  \n",
    "                          [ 3,  0,  0, -3,  0] ] )\n",
    "# state = np.array(initial_state)\n",
    "encoded_state = get_encoded_state_(state)\n",
    "tensor_state = torch.tensor(encoded_state, device=device).unsqueeze(0)\n",
    "\n",
    "## load Model and generate action probabilities and value state\n",
    "model = ResNet( 3, 32, device=device, board_size = board_size, actions_size = actions_size)\n",
    "model.load_state_dict(torch.load('model_supervised_2.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "policy, value = model(tensor_state)\n",
    "value = value.item()\n",
    "policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "print(value)\n",
    "\n",
    "#### adjust policy to only valid moves\n",
    "valid_moves = np.zeros_like(policy)\n",
    "for action_index in get_actions_indices_array(state, action_dict):\n",
    "    valid_moves[action_index] = 1.0\n",
    "\n",
    "policy *= valid_moves \n",
    "policy /= np.sum(policy)\n",
    "\n",
    "## Plot action space\n",
    "# Sort actions by their probabilities\n",
    "sorted_actions = np.argsort(policy)[::-1]\n",
    "\n",
    "# Select top 10 actions\n",
    "top_actions = sorted_actions[:10]\n",
    "\n",
    "# Plot the top 10 actions\n",
    "plot_top_actions(top_actions, policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bf7994",
   "metadata": {},
   "source": [
    "### 1.MCTS and Self Play"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e07397d",
   "metadata": {},
   "source": [
    "#### 1.1 MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4e168b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS() : \n",
    "\n",
    "    def __init__(self, model, args, device) :\n",
    "        self.args = args\n",
    "        self.model = model\n",
    " \n",
    "        super().__init__()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def search(self, state):\n",
    "#         define root \n",
    "        root = Node(self.args, state, visit_count=1)  ## board and state mean same thing \n",
    "        \n",
    "        ## add noise \n",
    "        policy, _ = self.model(\n",
    "                    torch.tensor(get_encoded_state_(state)).unsqueeze(0).to(device)\n",
    "                )\n",
    "\n",
    "        policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
    "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
    "            * np.random.dirichlet([self.args['dirichlet_alpha']] * actions_size)\n",
    "                \n",
    "        valid_moves = np.zeros_like(policy)\n",
    "        for action_index in get_actions_indices_array(state, action_dict):\n",
    "            valid_moves[action_index] = 1.0\n",
    "        \n",
    "        policy *= valid_moves \n",
    "        policy /= np.sum(policy)\n",
    "        root.expand(policy)\n",
    "\n",
    "        for search in range(self.args[\"num_searches\"]):\n",
    "            ## Selection \n",
    "            node = root\n",
    "\n",
    "            while node.is_fully_expanded():\n",
    "                node = node.select()\n",
    "\n",
    "            value, is_terminal = -get_score_array(node.board), is_finished_array(node.board)\n",
    "\n",
    "            if not is_terminal: \n",
    "         \n",
    "                policy, value = self.model(\n",
    "                    torch.tensor(get_encoded_state_(node.board)).unsqueeze(0).to(device)\n",
    "                ) \n",
    "                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
    "                valid_moves = np.zeros_like(policy)\n",
    "                for action_index in get_actions_indices_array(node.board,action_dict):\n",
    "                    valid_moves[action_index] = 1.0\n",
    "\n",
    "                policy *= valid_moves \n",
    "                policy /= np.sum(policy)\n",
    "\n",
    "                value = value.item()\n",
    "\n",
    "                ## Expansion\n",
    "                node = node.expand(policy)\n",
    "                \n",
    "            ## Backpropagation\n",
    "            node.backpropagate(value)\n",
    "\n",
    "        ## return visit counts \n",
    "        action_probs = [0] * actions_size\n",
    "\n",
    "        for child in root.children:\n",
    "            action_probs[child.action_taken] = child.visit_count\n",
    "\n",
    "        total_visit_count = sum(action_probs)\n",
    "        action_probs = np.array([prob / total_visit_count for prob in action_probs])\n",
    "        return action_probs, root\n",
    "\n",
    "class Node: \n",
    "    def __init__(self, args, board, parent=None, action_taken=None ,prior=0, visit_count=0):\n",
    "        self.args = args \n",
    "        self.board = board \n",
    "        self.parent = parent \n",
    "        self.action_taken = action_taken \n",
    "        self.prior = prior  \n",
    "\n",
    "        self.children = []\n",
    "        self.expandable_moves = list(get_actions_indices_array(board, action_dict))\n",
    "\n",
    "        self.visit_count = 0 \n",
    "        self.value_sum = 0 \n",
    "\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return  len(self.children)>0 \n",
    "    \n",
    "    def select(self):\n",
    "        best_child = None \n",
    "        best_ucb = -np.inf \n",
    "\n",
    "        for child in self.children : \n",
    "            ucb = self.get_ucb(child)\n",
    "            if ucb > best_ucb :\n",
    "                best_child = child \n",
    "                best_ucb = ucb \n",
    "\n",
    "        return best_child \n",
    "    \n",
    "    def get_ucb(self, child):\n",
    "        prior_score = child.prior * math.sqrt(self.visit_count) / (child.visit_count + 1)\n",
    "        if child.visit_count > 0:\n",
    "            value_score = child.value_sum / child.visit_count\n",
    "        else:\n",
    "            value_score = 0\n",
    "        return value_score + prior_score\n",
    "\n",
    "    def expand(self, policy):\n",
    "\n",
    "        for action_ind, prob in enumerate(policy):\n",
    "            if prob > 0 : \n",
    "                \n",
    "                ## Store position of cells and their current height that will be impacted by the move , so we can undo the move \n",
    "                store_move = []\n",
    "                action = index_to_action[action_ind]\n",
    "                store_move.append((action[0] , action[1] , self.board[action[0]][action[1]])) \n",
    "                store_move.append((action[2] , action[3] , self.board[action[2]][action[3]]))\n",
    "\n",
    "                ## play move \n",
    "                play_action_array(self.board,action)  \n",
    "\n",
    "                ## change perspective \n",
    "                self.board = -1 * np.array(self.board)\n",
    "                child_board = np.copy(self.board)\n",
    "                child = Node(self.args, child_board, self, action_ind, prob)\n",
    "                self.children.append(child)\n",
    "\n",
    "                ## Undo the move is restoring the cells that were changed by their old state \n",
    "                self.board = -1 * self.board\n",
    "                self.board[store_move[0][0]][store_move[0][1]] = store_move[0][2]\n",
    "                self.board[store_move[1][0]][store_move[1][1]] = store_move[1][2]\n",
    "                \n",
    "        return child\n",
    "\n",
    "\n",
    "    def backpropagate(self, value):\n",
    "        self.value_sum += value\n",
    "        self.visit_count += 1\n",
    "        \n",
    "        value = -value \n",
    "        if self.parent is not None:\n",
    "            self.parent.backpropagate(value)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28153b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best action index: 10\n",
      "Best action: (0, 2, 1, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## state Encoding \n",
    "state =  np.array(       [[ 1, -1,  1,  3,  0],  \n",
    "                          [ 1, -2,  3,  0,  0],  \n",
    "                          [ 0,  0,  0,  0,  1],  \n",
    "                          [ 0,  0, -3,  0,  0],  \n",
    "                          [ 3,  0,  0, -3,  0] ] )\n",
    "\n",
    "# state = np.array(initial_state)\n",
    "model = ResNet( 3, 32, device=device, board_size = board_size, actions_size = actions_size)\n",
    "model.load_state_dict(torch.load('model_supervised_2.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "args = {\n",
    "    'C': 1.25,\n",
    "    'num_searches': 2000,\n",
    "    'action_size': actions_size,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3, \n",
    "    'max_depth' : 100\n",
    "}\n",
    "\n",
    "mcts = MCTS(model, args, device)\n",
    "\n",
    "action_probs, root = mcts.search(state)\n",
    "\n",
    "best_action_index = np.argmax(action_probs)\n",
    "print(\"Best action index:\", best_action_index)\n",
    "best_action = index_to_action[best_action_index]\n",
    "print(\"Best action:\", best_action)\n",
    "\n",
    "# Sort actions by their probabilities\n",
    "sorted_actions = np.argsort(action_probs)[::-1]\n",
    "\n",
    "# Select top 10 actions\n",
    "top_actions = sorted_actions[:10]\n",
    "\n",
    "# Plot the top 10 actions\n",
    "plot_top_actions(top_actions, action_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e279d43d",
   "metadata": {},
   "source": [
    "#### 1.2 Self Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0df8178",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = [     [ 0, -1,  1, -1,  0],  \n",
    "                      [ 0,  1, -1,  1, -1],  \n",
    "                      [ 1, -1,  1, -1,  1],  \n",
    "                      [-1,  1, -1,  1,  0],  \n",
    "                      [ 1, -1,  1, -1,  0] ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "200cbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaZero():\n",
    "    def __init__(self, model, optimizer, args):\n",
    "        self.model = model \n",
    "        self.optimizer = optimizer \n",
    "        self.args = args \n",
    "        self.mcts = MCTS(model, args, device)\n",
    "    \n",
    "    def selfPlay(self):\n",
    "        memory = []\n",
    "        player = 1 \n",
    "        state = np.copy(initial_state) ## initialize game state \n",
    "\n",
    "        while True :       \n",
    "            action_probs, root = self.mcts.search(np.copy(state))\n",
    "            \n",
    "            memory.append((get_encoded_state_(state), action_probs, player))\n",
    "            \n",
    "            temperature_action_probs = np.array(action_probs) ** (1/self.args[\"temperature\"])\n",
    "            temperature_action_probs /= np.sum(temperature_action_probs)\n",
    "            action_index = np.random.choice(actions_size, p=temperature_action_probs)  ## this action is scalar \n",
    "            action = index_to_action[action_index]\n",
    "            \n",
    "            ## get to next state using action \n",
    "            play_action_array(state,action) \n",
    "\n",
    "            value, is_terminal = get_score_array(state), is_finished_array(state)\n",
    "\n",
    "            if is_terminal : \n",
    "                returnMemory = []\n",
    "                for hist_neutral_state_encoded, hist_action_probs, hist_player in memory : \n",
    "                    hist_outcome = value * hist_player \n",
    "                    returnMemory.append((\n",
    "                        hist_neutral_state_encoded, \n",
    "                        hist_action_probs, \n",
    "                        hist_outcome\n",
    "                    ))\n",
    "                return returnMemory\n",
    "            \n",
    "            ## change perspective \n",
    "            state = -1 * np.array(state)\n",
    "            player *= -1\n",
    "            \n",
    "            \n",
    "\n",
    "    def train(self, memory):\n",
    "        random.shuffle(memory)\n",
    "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
    "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])]\n",
    "            state, policy_targets, value_targets = zip(*sample)\n",
    "            \n",
    "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
    "            \n",
    "            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n",
    "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
    "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
    "            \n",
    "            out_policy, out_value = self.model(state)\n",
    "            \n",
    "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
    "            value_loss = F.mse_loss(out_value, value_targets)\n",
    "            loss = policy_loss + value_loss\n",
    "            \n",
    "            optimizer.zero_grad() # change to self.optimizer\n",
    "            loss.backward()\n",
    "            optimizer.step() # change to self.optimizer\n",
    "            \n",
    "            \n",
    "\n",
    "    def learn(self):\n",
    "        \n",
    "        for iteration in range(self.args[\"num_iterations\"]):\n",
    "            memory = []\n",
    "\n",
    "            self.model.eval()\n",
    "            ## machine plays with itself \n",
    "            for selfPlay_iteration in trange(self.args[\"num_selfPlay_iterations\"]):\n",
    "                memory += self.selfPlay()\n",
    "\n",
    "            ## train based on the memory collected\n",
    "            self.model.train()\n",
    "            for epoch in trange(self.args[\"num_epochs\"]):\n",
    "                self.train(memory)\n",
    "                \n",
    "            iteration += self.args[\"start_iteration\"]\n",
    "            torch.save(self.model.state_dict(), f\"model_{iteration}.pt\" )\n",
    "            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}.pt\")\n",
    "            return memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50938e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model = ResNet( 3, 32, device=device, board_size = board_size, actions_size = actions_size)\n",
    "# model.load_state_dict(torch.load('model_1.pt', map_location=device))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "# optimizer.load_state_dict(torch.load('optimizer_1.pt', map_location=device))\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 300,\n",
    "    'num_iterations': 3,\n",
    "    'start_iteration': 0,\n",
    "    'num_parallel_games': 10,\n",
    "    'num_selfPlay_iterations': 100,\n",
    "    'num_epochs': 5,\n",
    "    'batch_size': 64,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "}\n",
    "\n",
    "alphaZero = AlphaZero(model, optimizer, args)\n",
    "\n",
    "start_time = time.time()\n",
    "memory_ = alphaZero.learn()\n",
    "end_time = time.time()\n",
    "\n",
    "time_difference = end_time - start_time\n",
    "print(f'The code took {time_difference:.2f} seconds to run.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f2c04f",
   "metadata": {},
   "source": [
    "This part is to check the memory and if all is good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038dc5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batchIdx in range(0, len(memory), args['batch_size']):\n",
    "sample = memory_\n",
    "states, policy_targets, value_targets = zip(*sample)\n",
    "\n",
    "states, policy_targets, value_targets = np.array(states), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(states)):\n",
    "    \n",
    "    print(\"state \"+str(i)+\" : score is : \"+str(get_score_array(get_decoded_state(states[i])))\n",
    "     + \" number of moves : \" + str(len(list(get_actions_indices_array(get_decoded_state(states[i]) , action_dict)))))\n",
    "    print(get_decoded_state(states[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86493340",
   "metadata": {},
   "source": [
    "#### 1.3Play against Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ec9f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet( 3, 32, device=device, board_size = board_size, actions_size = actions_size)\n",
    "model.load_state_dict(torch.load('model_paral_2.pt', map_location=device))\n",
    "\n",
    "args = {\n",
    "    'C': 1.25,\n",
    "    'num_searches': 500,\n",
    "    'action_size': actions_size,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3, \n",
    "    'max_depth':4\n",
    "}\n",
    "mcts = MCTS(model, args, device)\n",
    "agent_args = {'model': model, 'mcts': mcts, 'args': args}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f130de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Self Play agent\n",
    "def self_play_agent(state, model, mcts, args, player):\n",
    "    if model : \n",
    "        model.eval()\n",
    "    action_probs, root = mcts.search(np.copy(state) * player)\n",
    "    best_action_index = np.argmax(action_probs)\n",
    "    best_action = index_to_action[best_action_index]\n",
    "    return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9be799fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## random Agent\n",
    "import random\n",
    "\n",
    "def random_agent(state, player):\n",
    "    valid_actions = [action for action in index_to_action.values() if is_action_valid_array(state, action)]\n",
    "    return random.choice(valid_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "134365e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(agent1, agent2, agent1_args=None, agent2_args=None, display=True):\n",
    "    if agent1_args is None:\n",
    "        agent1_args = {}\n",
    "    if agent2_args is None:\n",
    "        agent2_args = {}\n",
    "\n",
    "    state = np.array(initial_state)\n",
    "    is_terminal = False\n",
    "    move_number = 1\n",
    "    score = 0\n",
    "\n",
    "    while not is_terminal:\n",
    "        if display:\n",
    "            print(f\"Move number {move_number}:\")\n",
    "            print(\"State:\")\n",
    "            print(state)\n",
    "            print(f\"Score: {score}\")\n",
    "\n",
    "        if move_number % 2 == 1:\n",
    "            action = agent1(state, **agent1_args, player=1)\n",
    "        else:\n",
    "            action = agent2(state, **agent2_args, player=-1)\n",
    "\n",
    "        play_action_array(state, action)\n",
    "        score, is_terminal = get_score_array(state), is_finished_array(state)\n",
    "\n",
    "        if display:\n",
    "            print(f\"Action played: {action}\\n\")\n",
    "\n",
    "        move_number += 1\n",
    "\n",
    "    if display:\n",
    "        print(\"Final state:\")\n",
    "        print(state)\n",
    "        print(f\"Final score: {score}\")\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90397754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game between self_play_agent and random_agent:\n",
      "Move number 1:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: 0\n",
      "Action played: (2, 2, 1, 3)\n",
      "\n",
      "Move number 2:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  2 -1]\n",
      " [ 1 -1  0 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: -0.1\n",
      "Action played: (1, 2, 1, 1)\n",
      "\n",
      "Move number 3:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0 -2  0  2 -1]\n",
      " [ 1 -1  0 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: -0.2\n",
      "Action played: (2, 4, 3, 3)\n",
      "\n",
      "Move number 4:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0 -2  0  2 -1]\n",
      " [ 1 -1  0 -1  0]\n",
      " [-1  1 -1  2  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: -0.3\n",
      "Action played: (3, 1, 3, 2)\n",
      "\n",
      "Move number 5:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0 -2  0  2 -1]\n",
      " [ 1 -1  0 -1  0]\n",
      " [-1  0  2  2  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: -0.2\n",
      "Action played: (3, 2, 2, 1)\n",
      "\n",
      "Move number 6:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0 -2  0  2 -1]\n",
      " [ 1  3  0 -1  0]\n",
      " [-1  0  0  2  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: -0.1\n",
      "Action played: (4, 0, 3, 0)\n",
      "\n",
      "Move number 7:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0 -2  0  2 -1]\n",
      " [ 1  3  0 -1  0]\n",
      " [ 2  0  0  2  0]\n",
      " [ 0 -1  1 -1  0]]\n",
      "Score: 0.1\n",
      "Action played: (4, 2, 4, 3)\n",
      "\n",
      "Move number 8:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0 -2  0  2 -1]\n",
      " [ 1  3  0 -1  0]\n",
      " [ 2  0  0  2  0]\n",
      " [ 0 -1  0  2  0]]\n",
      "Score: 0.1\n",
      "Action played: (2, 0, 1, 1)\n",
      "\n",
      "Move number 9:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  3  0  2 -1]\n",
      " [ 0  3  0 -1  0]\n",
      " [ 2  0  0  2  0]\n",
      " [ 0 -1  0  2  0]]\n",
      "Score: 0.2\n",
      "Action played: (0, 2, 1, 3)\n",
      "\n",
      "Move number 10:\n",
      "State:\n",
      "[[ 0 -1  0 -1  0]\n",
      " [ 0  3  0  3 -1]\n",
      " [ 0  3  0 -1  0]\n",
      " [ 2  0  0  2  0]\n",
      " [ 0 -1  0  2  0]]\n",
      "Score: 0.1\n",
      "Action played: (3, 0, 4, 1)\n",
      "\n",
      "Move number 11:\n",
      "State:\n",
      "[[ 0 -1  0 -1  0]\n",
      " [ 0  3  0  3 -1]\n",
      " [ 0  3  0 -1  0]\n",
      " [ 0  0  0  2  0]\n",
      " [ 0  3  0  2  0]]\n",
      "Score: 0.2\n",
      "Action played: (2, 3, 1, 4)\n",
      "\n",
      "Move number 12:\n",
      "State:\n",
      "[[ 0 -1  0 -1  0]\n",
      " [ 0  3  0  3 -2]\n",
      " [ 0  3  0  0  0]\n",
      " [ 0  0  0  2  0]\n",
      " [ 0  3  0  2  0]]\n",
      "Score: 0.3\n",
      "Action played: (1, 4, 0, 3)\n",
      "\n",
      "Final state:\n",
      "[[ 0 -1  0 -3  0]\n",
      " [ 0  3  0  3  0]\n",
      " [ 0  3  0  0  0]\n",
      " [ 0  0  0  2  0]\n",
      " [ 0  3  0  2  0]]\n",
      "Final score: 0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generate Game between Self Play agent and Random\n",
    "agent_args = {'model': model, 'mcts': mcts, 'args': args}\n",
    "\n",
    "print(\"Game between self_play_agent and random_agent:\")\n",
    "play_game(self_play_agent, random_agent, agent1_args=agent_args)\n",
    "# play_game(random_agent, self_play_agent, agent2_args=agent_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4f400",
   "metadata": {},
   "source": [
    "As we can see : Perfect result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443e9ac",
   "metadata": {},
   "source": [
    "#### 1.4 Play against Greedy Player "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65bdb383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_agent(state, player):\n",
    "    actions = get_actions_array(state)\n",
    "    \n",
    "    def predict_score(state, action):\n",
    "        new_state = play_action_array(state.copy(), action)\n",
    "        i2, j2 = action[2], action[3]\n",
    "        return  new_state[i2][j2]\n",
    "    \n",
    "    order = [player*3,player*2,player*1, player*-1,-player*2,-player*3]\n",
    "    srt = {b: i for i, b in enumerate(order)}\n",
    "    sorted_actions = sorted(actions, key=lambda a: srt[predict_score(state, a)])\n",
    "\n",
    "        \n",
    "#     sorted_actions = sorted(actions, key=lambda a: predict_score(state, a), reverse=True)\n",
    "    best_action = sorted_actions[0]\n",
    "\n",
    "    return best_action\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ecfb2b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Game between self_play_agent and greedy_agent:\n",
      "Move number 1:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: 0\n",
      "Action played: (4, 0, 4, 1)\n",
      "\n",
      "Move number 2:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 0  2  1 -1  0]]\n",
      "Score: 0.1\n",
      "Action played: (3, 0, 4, 1)\n",
      "\n",
      "Move number 3:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [ 0  1 -1  1  0]\n",
      " [ 0 -3  1 -1  0]]\n",
      "Score: -0.1\n",
      "Action played: (2, 4, 1, 4)\n",
      "\n",
      "Move number 4:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1  2]\n",
      " [ 1 -1  1 -1  0]\n",
      " [ 0  1 -1  1  0]\n",
      " [ 0 -3  1 -1  0]]\n",
      "Score: 0.1\n",
      "Action played: (0, 3, 1, 4)\n",
      "\n",
      "Move number 5:\n",
      "State:\n",
      "[[ 0 -1  1  0  0]\n",
      " [ 0  1 -1  1 -3]\n",
      " [ 1 -1  1 -1  0]\n",
      " [ 0  1 -1  1  0]\n",
      " [ 0 -3  1 -1  0]]\n",
      "Score: -0.2\n",
      "Action played: (3, 3, 2, 3)\n",
      "\n",
      "Move number 6:\n",
      "State:\n",
      "[[ 0 -1  1  0  0]\n",
      " [ 0  1 -1  1 -3]\n",
      " [ 1 -1  1  2  0]\n",
      " [ 0  1 -1  0  0]\n",
      " [ 0 -3  1 -1  0]]\n",
      "Score: 0.1\n",
      "Action played: (1, 2, 2, 3)\n",
      "\n",
      "Move number 7:\n",
      "State:\n",
      "[[ 0 -1  1  0  0]\n",
      " [ 0  1  0  1 -3]\n",
      " [ 1 -1  1 -3  0]\n",
      " [ 0  1 -1  0  0]\n",
      " [ 0 -3  1 -1  0]]\n",
      "Score: -0.3\n",
      "Action played: (4, 2, 4, 3)\n",
      "\n",
      "Move number 8:\n",
      "State:\n",
      "[[ 0 -1  1  0  0]\n",
      " [ 0  1  0  1 -3]\n",
      " [ 1 -1  1 -3  0]\n",
      " [ 0  1 -1  0  0]\n",
      " [ 0 -3  0  2  0]]\n",
      "Score: 0.1\n",
      "Action played: (3, 2, 4, 3)\n",
      "\n",
      "Move number 9:\n",
      "State:\n",
      "[[ 0 -1  1  0  0]\n",
      " [ 0  1  0  1 -3]\n",
      " [ 1 -1  1 -3  0]\n",
      " [ 0  1  0  0  0]\n",
      " [ 0 -3  0 -3  0]]\n",
      "Score: -0.4\n",
      "Action played: (0, 1, 0, 2)\n",
      "\n",
      "Move number 10:\n",
      "State:\n",
      "[[ 0  0 -2  0  0]\n",
      " [ 0  1  0  1 -3]\n",
      " [ 1 -1  1 -3  0]\n",
      " [ 0  1  0  0  0]\n",
      " [ 0 -3  0 -3  0]]\n",
      "Score: -0.1\n",
      "Action played: (0, 2, 1, 1)\n",
      "\n",
      "Move number 11:\n",
      "State:\n",
      "[[ 0  0  0  0  0]\n",
      " [ 0 -3  0  1 -3]\n",
      " [ 1 -1  1 -3  0]\n",
      " [ 0  1  0  0  0]\n",
      " [ 0 -3  0 -3  0]]\n",
      "Score: -0.2\n",
      "Action played: (2, 2, 2, 1)\n",
      "\n",
      "Move number 12:\n",
      "State:\n",
      "[[ 0  0  0  0  0]\n",
      " [ 0 -3  0  1 -3]\n",
      " [ 1  2  0 -3  0]\n",
      " [ 0  1  0  0  0]\n",
      " [ 0 -3  0 -3  0]]\n",
      "Score: -0.1\n",
      "Action played: (2, 0, 3, 1)\n",
      "\n",
      "Final state:\n",
      "[[ 0  0  0  0  0]\n",
      " [ 0 -3  0  1 -3]\n",
      " [ 0  2  0 -3  0]\n",
      " [ 0  2  0  0  0]\n",
      " [ 0 -3  0 -3  0]]\n",
      "Final score: -0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nGame between self_play_agent and greedy_agent:\")\n",
    "play_game(self_play_agent, greedy_agent, agent1_args=agent_args)\n",
    "# play_game(greedy_agent, self_play_agent, agent2_args=agent_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5bd214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def play_games(num_games, agent1, agent2, agent1_args=None, agent2_args=None):\n",
    "    agent1_wins = 0\n",
    "    agent2_wins = 0\n",
    "    draws = 0\n",
    "\n",
    "    for i in range(num_games):\n",
    "        score = play_game(agent1, agent2, agent1_args, agent2_args, display=False)\n",
    "        if score > 0:\n",
    "            agent1_wins += 1\n",
    "        elif score < 0:\n",
    "            agent2_wins += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "\n",
    "    return agent1_wins, agent2_wins, draws\n",
    "\n",
    "num_games = 20\n",
    "agent1_args = {'model': model, 'mcts': mcts, 'args': args}\n",
    "\n",
    "self_play_vs_random = play_games(num_games, self_play_agent, random_agent, agent1_args=agent1_args)\n",
    "self_play_vs_greedy = play_games(num_games, self_play_agent, greedy_agent, agent1_args=agent1_args)\n",
    "\n",
    "# Plotting results\n",
    "x = np.arange(3)\n",
    "width = 0.3\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, self_play_vs_random, width, label='Self Play vs Random')\n",
    "rects2 = ax.bar(x + width/2, self_play_vs_greedy, width, label='Self Play vs Greedy')\n",
    "\n",
    "ax.set_ylabel('Number of Games')\n",
    "ax.set_title('Self Play Agent Performance against Random and Greedy Agents')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Wins', 'Losses', 'Draws'])\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1c332",
   "metadata": {},
   "source": [
    "We can say that for mini-Avalam of size 3x3, we have already a very good model that can beat random player and Greedy player all the time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d6cec",
   "metadata": {},
   "source": [
    "### 2.Parallelization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beed05ce",
   "metadata": {},
   "source": [
    "#### 2.1 MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab7d73a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSParallel:\n",
    "\n",
    "    def __init__(self, model, args, device):\n",
    "        self.args = args\n",
    "        self.model = model\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def search(self, states, spGames):\n",
    "\n",
    "        policy, _ = self.model(\n",
    "            torch.tensor(get_encoded_states(states), device=self.model.device)\n",
    "        )\n",
    "        policy = torch.softmax(policy, axis=1).cpu().numpy()\n",
    "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
    "            * np.random.dirichlet([self.args['dirichlet_alpha']] * actions_size, size=policy.shape[0])\n",
    "\n",
    "        for i, spg in enumerate(spGames):\n",
    "\n",
    "            spg_policy = policy[i]\n",
    "            valid_moves = np.zeros_like(spg_policy)\n",
    "            for action_index in get_actions_indices_array(states[i], action_dict):\n",
    "                valid_moves[action_index] = 1.0\n",
    "\n",
    "            spg_policy *= valid_moves\n",
    "            spg_policy /= np.sum(spg_policy)\n",
    "\n",
    "            spg.root = Node(self.args, states[i], visit_count=1)\n",
    "            spg.root.expand(spg_policy)\n",
    "\n",
    "        for search in range(self.args[\"num_searches\"]):\n",
    "            for spg in spGames:\n",
    "                spg.node = None\n",
    "                node = spg.root\n",
    "\n",
    "                while node.is_fully_expanded():\n",
    "                    node = node.select()\n",
    "\n",
    "                value, is_terminal = -get_score_array(node.board), is_finished_array(node.board)\n",
    "\n",
    "                if is_terminal:\n",
    "                    node.backpropagate(value)\n",
    "                else:\n",
    "                    spg.node = node\n",
    "\n",
    "            expandable_spGames = [mappingIdx for mappingIdx in range(len(spGames)) if spGames[mappingIdx].node is not None]\n",
    "\n",
    "            if len(expandable_spGames) > 0:\n",
    "                states = np.stack([spGames[mappingIdx].node.board for mappingIdx in expandable_spGames])\n",
    "\n",
    "                policy, value = self.model(\n",
    "                    torch.tensor(get_encoded_states(states)).to(device)\n",
    "                )\n",
    "                policy = torch.softmax(policy, axis=1).cpu().numpy()\n",
    "                value = value.cpu().numpy()\n",
    "\n",
    "                for i, mappingIdx in enumerate(expandable_spGames):\n",
    "                    node = spGames[mappingIdx].node\n",
    "                    spg_policy, spg_value = policy[i], value[i].item()\n",
    "\n",
    "                    valid_moves = np.zeros_like(spg_policy)\n",
    "                    for action_index in get_actions_indices_array(node.board, action_dict):\n",
    "                        valid_moves[action_index] = 1.0\n",
    "\n",
    "                    spg_policy *= valid_moves\n",
    "                    spg_policy /= np.sum(spg_policy)\n",
    "                    \n",
    "                    node.expand(spg_policy)\n",
    "                    node.backpropagate(spg_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a94986",
   "metadata": {},
   "source": [
    "#### 2.2 Self Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fee2e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaZeroParallel():\n",
    "    def __init__(self, model, optimizer, args):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.args = args\n",
    "        self.mcts = MCTSParallel(model, args, device)\n",
    "\n",
    "    def selfPlay(self):\n",
    "        return_memory = []\n",
    "        player = 1\n",
    "        spGames = [SPG() for spg in range(self.args[\"num_parallel_games\"])]\n",
    "\n",
    "        while len(spGames) > 0:\n",
    "\n",
    "            states = np.stack([spg.state for spg in spGames])\n",
    "            \n",
    "\n",
    "            self.mcts.search(states, spGames)\n",
    "\n",
    "            for i in range(len(spGames))[::-1]:\n",
    "\n",
    "                spg = spGames[i]\n",
    "\n",
    "                ## return visit counts\n",
    "                action_probs = np.zeros(actions_size)\n",
    "                for child in spg.root.children:\n",
    "                    action_probs[child.action_taken] = child.visit_count\n",
    "                action_probs /= np.sum(action_probs)\n",
    "                \n",
    "                \n",
    "                spg.memory.append((spg.state.copy(), action_probs, player))\n",
    "\n",
    "                temperature_action_probs = action_probs ** (1 / self.args[\"temperature\"])\n",
    "                temperature_action_probs /= np.sum(temperature_action_probs)\n",
    "                \n",
    "                action_index = np.random.choice(actions_size, p=temperature_action_probs)\n",
    "                action = index_to_action[action_index]\n",
    "\n",
    "                ## get to the next state using action\n",
    "                spg.state = play_action_array(spg.state, action)\n",
    "                \n",
    "                ## change perspective \n",
    "                spg.state *= -1 \n",
    "\n",
    "                is_terminal = is_finished_array(spg.state)\n",
    "\n",
    "                if is_terminal:\n",
    "                    for hist_neutral_state, hist_action_probs, hist_player in spg.memory:\n",
    "                        value = -get_score_array(spg.state) * hist_player \n",
    "                        hist_outcome = value\n",
    "                        \n",
    "                        ## Normal Training\n",
    "#                         return_memory.append((\n",
    "#                             get_encoded_state_(hist_neutral_state),\n",
    "#                             hist_action_probs,\n",
    "#                             hist_outcome\n",
    "#                         ))\n",
    "                        ### data augmentation \n",
    "                        combinations = generate_combinations(hist_neutral_state, hist_action_probs, hist_outcome)\n",
    "                        return_memory.extend(combinations)\n",
    "                \n",
    "#                         return_memory.append(generate_combinations(hist_neutral_state, hist_action_probs, hist_outcome))\n",
    "                    ## remove game after it's finished\n",
    "                    del spGames[i]\n",
    "        \n",
    "                \n",
    "\n",
    "            player *= -1\n",
    "\n",
    "        return return_memory\n",
    "\n",
    "\n",
    "    def train(self, memory):\n",
    "        random.shuffle(memory)\n",
    "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
    "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])]\n",
    "            state, policy_targets, value_targets = zip(*sample)\n",
    "            \n",
    "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
    "            \n",
    "            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n",
    "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
    "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
    "            \n",
    "            out_policy, out_value = self.model(state)\n",
    "            \n",
    "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
    "            value_loss = F.mse_loss(out_value, value_targets)\n",
    "            loss = policy_loss + value_loss\n",
    "            \n",
    "            optimizer.zero_grad() # change to self.optimizer\n",
    "            loss.backward()\n",
    "            optimizer.step() # change to self.optimizer\n",
    "            \n",
    "            \n",
    "\n",
    "    def learn(self):\n",
    "        for iteration in range(self.args[\"num_iterations\"] ):\n",
    "            memory = []\n",
    "\n",
    "            self.model.eval()\n",
    "            ## machine plays with itself \n",
    "            for selfPlay_iteration in trange(self.args[\"num_selfPlay_iterations\"]//self.args[\"num_parallel_games\"]):\n",
    "                memory += self.selfPlay()\n",
    "\n",
    "            ## train based on the memory collected\n",
    "            self.model.train()\n",
    "            for epoch in trange(self.args[\"num_epochs\"]):\n",
    "                self.train(memory)\n",
    "                \n",
    "            iteration += self.args[\"start_iteration\"]\n",
    "            torch.save(self.model.state_dict(), f\"model_paral_{iteration}.pt\" )\n",
    "            torch.save(self.optimizer.state_dict(), f\"optimizer_paral_{iteration}.pt\")\n",
    "        return memory\n",
    "            \n",
    "class SPG:\n",
    "    def __init__(self):\n",
    "        self.state = np.copy(initial_state)\n",
    "        self.memory = []\n",
    "        self.root = None \n",
    "        self.node = None \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96670699",
   "metadata": {},
   "source": [
    "#### 2.3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ab00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model = ResNet( 3, 32, device=device, board_size = board_size, actions_size = actions_size)\n",
    "model.load_state_dict(torch.load('model_paral_2.pt', map_location=device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "optimizer.load_state_dict(torch.load('optimizer_paral_2.pt', map_location=device))\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 500,\n",
    "    'num_iterations': 1,\n",
    "    'start_iteration': 3, ### DONT FORGET \n",
    "    'num_parallel_games': 50,\n",
    "    'num_selfPlay_iterations': 50,\n",
    "    'num_epochs': 5,\n",
    "    'batch_size': 64,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3, \n",
    "    'max_depth':100\n",
    "}\n",
    "\n",
    "alphaZero = AlphaZeroParallel(model, optimizer, args)\n",
    "\n",
    "start_time = time.time()\n",
    "memory = alphaZero.learn()\n",
    "end_time = time.time()\n",
    "\n",
    "time_difference = end_time - start_time\n",
    "print(f'The code took {time_difference:.2f} seconds to run.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ef47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batchIdx in range(0, len(memory), args['batch_size']):\n",
    "sample = memory\n",
    "states, policy_targets, value_targets = zip(*sample)\n",
    "\n",
    "states, policy_targets, value_targets = np.array(states), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885eadf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(states)):\n",
    "    \n",
    "    print(\"state \"+str(i)+\" : score is : \"+str(get_score_array(get_decoded_state(states[i])))\n",
    "     + \" number of moves : \" + str(len(list(get_actions_indices_array(get_decoded_state(states[i]) , action_dict)))))\n",
    "    print(get_decoded_state(states[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35480785",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in value_targets :\n",
    "    print(v[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e798f9a0",
   "metadata": {},
   "source": [
    "#### 2.4 Play against older version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1cde9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = ResNet( 3, 32, device=device, board_size = board_size, actions_size = actions_size)\n",
    "model_1.load_state_dict(torch.load('model_paral_2.pt', map_location=device))\n",
    "\n",
    "model_2 = ResNet( 3, 32, device=device, board_size = board_size, actions_size = actions_size)\n",
    "model_2.load_state_dict(torch.load('model_paral_1.pt', map_location=device))\n",
    "\n",
    "args = {\n",
    "    'C': 1.25,\n",
    "    'num_searches': 1500,\n",
    "    'action_size': actions_size,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3, \n",
    "    'max_depth': 100\n",
    "}\n",
    "mcts_1 = MCTS(model_1, args, device)\n",
    "mcts_2 = MCTS(model_2, args, device)\n",
    "\n",
    "agent1_args = {'model': model_1, 'mcts': mcts_1, 'args': args}\n",
    "agent2_args = {'model': model_2, 'mcts': mcts_2, 'args': args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e942cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGame between self_play_agent_v1 and self_play_agent_v2\")\n",
    "# play_game(self_play_agent, greedy_agent, agent1_args=agent1_args)\n",
    "# play_game(greedy_agent, self_play_agent, agent2_args=agent1_args)\n",
    "play_game(self_play_agent, self_play_agent, agent1_args=agent1_args, agent2_args=agent2_args)\n",
    "play_game(self_play_agent, self_play_agent, agent1_args=agent2_args, agent2_args=agent1_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86abdf8b",
   "metadata": {},
   "source": [
    "#### 2.5 PLay against Greedy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet( 3, 32, device=device, board_size = board_size, actions_size = actions_size)\n",
    "model.load_state_dict(torch.load('model_paral_3.pt', map_location=device))\n",
    "\n",
    "args = {\n",
    "    'C': 1.25,\n",
    "    'num_searches': 2000,\n",
    "    'action_size': actions_size,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3, \n",
    "    'max_depth':5\n",
    "}\n",
    "agent_args = {'model': model, 'mcts': mcts, 'args': args}\n",
    "mcts = MCTS(model, args, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96414d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGame between self_play_agent and greedy_agent:\")\n",
    "# play_game(self_play_agent, greedy_agent, agent1_args=agent_args)\n",
    "play_game(greedy_agent, self_play_agent, agent2_args=agent_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def play_games(num_games, agent1, agent2, agent1_args=None, agent2_args=None):\n",
    "    agent1_wins = 0\n",
    "    agent2_wins = 0\n",
    "    draws = 0\n",
    "\n",
    "    for i in range(num_games):\n",
    "        score = play_game(agent1, agent2, agent1_args, agent2_args, display=False)\n",
    "        if score > 0:\n",
    "            agent1_wins += 1\n",
    "        elif score < 0:\n",
    "            agent2_wins += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "\n",
    "    return agent1_wins, agent2_wins, draws\n",
    "\n",
    "num_games = 5\n",
    "# agent1_args = {'model': model, 'mcts': mcts, 'args': args}\n",
    "\n",
    "self_play_vs_random = play_games(num_games, self_play_agent, random_agent, agent1_args=agent_args)\n",
    "self_play_vs_greedy = play_games(num_games, self_play_agent, greedy_agent, agent1_args=agent_args)\n",
    "\n",
    "# Plotting results\n",
    "x = np.arange(3)\n",
    "width = 0.3\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, self_play_vs_random, width, label='Self Play vs Random')\n",
    "rects2 = ax.bar(x + width/2, self_play_vs_greedy, width, label='Self Play vs Greedy')\n",
    "\n",
    "ax.set_ylabel('Number of Games')\n",
    "ax.set_title('Self Play Agent Performance against Random and Greedy Agents')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Wins', 'Losses', 'Draws'])\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a110af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_play_vs_greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b0a832",
   "metadata": {},
   "source": [
    "### 3.Training using Pre-built agents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b035e",
   "metadata": {},
   "source": [
    "#### 3.1 Heuristics Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f28b4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions_ranked (board , limit_moves ,max_player): \n",
    "    \"\"\"Yield all valid actions on this board.\"\"\"\n",
    "    \n",
    "    scores = []\n",
    "    actions = []\n",
    "\n",
    "    towers = get_towers_array(board)\n",
    "    towers_position = {(x,y) for x,y,z in towers}\n",
    "    \n",
    "    \n",
    "    for i, j, h in get_towers_array(board):\n",
    "        for action in get_tower_actions_array(board, i, j):\n",
    "            i1, j1, i2, j2 = action\n",
    "            h1 = abs(board[i1][j1])\n",
    "            h2 = abs(board[i2][j2])\n",
    "\n",
    "            score = 0 \n",
    "            visited = {}\n",
    "            \n",
    "            ###### Heuristic 1 for Isolate Pawns :\n",
    "            ## Store position of cells and their current height that will be impacted by the move , so we can undo the move \n",
    "            store_move = []\n",
    "            store_move.append(( i1, j1 , board[i1][j1])) \n",
    "            store_move.append(( i2, j2 , board[i2][j2]))\n",
    "\n",
    "            # play action on board\n",
    "            play_action_array(board, action) \n",
    "\n",
    "            # check if move yielded isolated pawns (neighbors of (i,j)cell)\n",
    "            for i_ in range(i1-1 , i1+2, 1) :\n",
    "                for j_ in range(j1-1, j1+2 ,1) :\n",
    "                    if (i_,j_) in towers_position : \n",
    "                        if not is_tower_movable(board,i_, j_) and board[i_][j_] != 0 and abs(board[i_][j_]) != 5 :\n",
    "                            visited[(i,j)] = True\n",
    "                            score += 3 * board[i_][j_] / abs(board[i_][j_] )    \n",
    "\n",
    "            \n",
    "            ## Undo the move is restoring the cells that were changed by their old state \n",
    "            board[store_move[0][0]][store_move[0][1]] = store_move[0][2]\n",
    "            board[store_move[1][0]][store_move[1][1]] = store_move[1][2]\n",
    "            ########\n",
    "\n",
    "\n",
    "            ###### Heuristic 2 : If Move result on tours with heigher weight \n",
    "            if board[i1][j1] < 0 and (i,j) not in visited: ## yellow on top\n",
    "                score += -(h1 + h2)\n",
    "            elif board[i1][j1] > 0 and (i,j) not in visited :\n",
    "                score += h1 + h2\n",
    "\n",
    "            ###### Heuristic 3: Moves where you put your own stone on top of another yours is generally weak\n",
    "            if  board[i1][j1] * board[i2][j2] >= 1 :\n",
    "                score -= 2.5 * board[i1][j1] / abs(board[i1][j1] )\n",
    "\n",
    "            # store new score resulted from the action \n",
    "            scores.append(score)\n",
    "            actions.append(action) \n",
    "    \n",
    "    return [x for _, x in sorted(zip(scores, actions) ,reverse =  max_player)][:limit_moves] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "087e579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_board(board  ):\n",
    "        \n",
    "    score = 0\n",
    "    visited = set()\n",
    "\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            \n",
    "            if board[i][j] == 0 :\n",
    "                pass\n",
    "            \n",
    "            ## assign 1.55 points to Tour \n",
    "            elif board[i][j] in (-3,3) :\n",
    "                score += 1.55 * board[i][j] / abs(board[i][j] )\n",
    "\n",
    "            ## assign 3 points to isolated Powns \n",
    "            elif not is_tower_movable_array(board, i, j):\n",
    "                score += 1.5 * board[i][j] / abs(board[i][j] )\n",
    "                \n",
    "            ## assign 1 point to the rest of the Pawns if not isolated group of pawns , otherwise assign the correct value as explained in the report \n",
    "            else :\n",
    "                ## if already visited assign one point to that pawn \n",
    "                if (i,j) in visited :\n",
    "                    score += board[i][j] / abs(board[i][j] )\n",
    "                \n",
    "                ## if never visited , check the existence of isolated group of pawns \n",
    "                else :\n",
    "                    color = board[i][j] / abs(board[i][j] )\n",
    "                    cycle = [(i,j)]\n",
    "                    cycle_sum = 3 - abs(board[i][j])\n",
    "                    same_color = True \n",
    "                    nodes_visited = -1 \n",
    "\n",
    "                    \n",
    "                    while ( cycle_sum >= 0 and cycle != [] and same_color ) :\n",
    "\n",
    "                        current = cycle.pop()\n",
    "\n",
    "                         ## look neighbors \n",
    "                        for action in get_tower_actions_array(board, current[0] , current[1]):               \n",
    "                            i1, j1, i2, j2 = action\n",
    "                            ## if same color , continue \n",
    "                            if board[i2][j2] / abs(board[i2][j2] ) != color :\n",
    "                                same_color = False \n",
    "                                \n",
    "                            if current not in visited : \n",
    "                                cycle.append((i2,j2))\n",
    "                                visited.add((i2,j2))\n",
    "                                cycle_sum -= abs(board[i2][j2])\n",
    "                        \n",
    "                        nodes_visited += 1 \n",
    "\n",
    "                    ## if already more than 5 or color is changed , assign one point . \n",
    "                    if cycle != [] or same_color == False : \n",
    "                        score += board[i][j] / abs(board[i][j] ) \n",
    "\n",
    "                    ## if its one group isolated of pawns , assign 1.55 if their sum is 5 (equivalent to 1 Tour ) \n",
    "                    ## and 1.5 if their sum is less than 5 (Equivalent to isolated pawn)   \n",
    "                    else : \n",
    "                        if cycle_sum == 3 : \n",
    "                            score += 1.55 * color - nodes_visited * 1 * color \n",
    "                        else :\n",
    "                            score += 1.5 * color - nodes_visited * 1 * color \n",
    "                    \n",
    "                \n",
    "    return score \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c43dc0",
   "metadata": {},
   "source": [
    "#### 3.2 MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51507223",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS_Supervised() : \n",
    "\n",
    "    def __init__(self, args, device) :\n",
    "        self.args = args\n",
    " \n",
    "        super().__init__()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def search(self, state):\n",
    "#         define root \n",
    "        root = Node(self.args, state, visit_count=1)  ## board and state mean same thing \n",
    "        \n",
    "        value = score_board(root.board)\n",
    "        actions = get_actions_ranked(root.board , 20 , 1)\n",
    "        actions  = list(actions)\n",
    "\n",
    "\n",
    "        n = len(actions)\n",
    "        base_probs = [0.3, 0.25, 0.2, 0.15, 0.1]\n",
    "        remaining_prob = 1 - sum(base_probs)\n",
    "        equal_prob = remaining_prob / (n - len(base_probs))\n",
    "\n",
    "        probs = base_probs + [equal_prob] * (n - len(base_probs))\n",
    "\n",
    "        policy = np.zeros(actions_size)\n",
    "        for i, action in enumerate(actions):\n",
    "            action_index = action_dict[action]\n",
    "            policy[action_index] = probs[i]\n",
    "        \n",
    "        root.expand(policy)\n",
    "\n",
    "        for search in range(self.args[\"num_searches\"]):\n",
    "            ## Selection \n",
    "            node = root\n",
    "\n",
    "            while node.is_fully_expanded():\n",
    "                node = node.select()\n",
    "\n",
    "            value, is_terminal = -get_score_array(node.board), is_finished_array(node.board)\n",
    "\n",
    "            if not is_terminal: \n",
    "         \n",
    "                value = score_board(node.board)\n",
    "                actions = get_actions_ranked(node.board , 20 , 1)\n",
    "                actions  = list(actions)\n",
    "\n",
    "                policy = np.zeros(9*9*8)\n",
    "\n",
    "                n = len(actions)\n",
    "                base_probs = [0.5, 0.3, 0.2]\n",
    "                remaining_prob = 1 - sum(base_probs)\n",
    "                equal_prob = remaining_prob / (n - len(base_probs))\n",
    "\n",
    "                probs = base_probs + [equal_prob] * (n - len(base_probs))\n",
    "\n",
    "                policy = np.zeros(9*9*8)\n",
    "                for i, action in enumerate(actions):\n",
    "                    action_index = action_dict[action]\n",
    "                    policy[action_index] = probs[i]\n",
    "\n",
    "                ## Expansion\n",
    "                node = node.expand(policy)\n",
    "                \n",
    "            ## Backpropagation\n",
    "            node.backpropagate(value)\n",
    "\n",
    "        ## return visit counts \n",
    "        action_probs = [0] * actions_size\n",
    "\n",
    "        for child in root.children:\n",
    "            action_probs[child.action_taken] = child.visit_count\n",
    "\n",
    "        total_visit_count = sum(action_probs)\n",
    "        action_probs = np.array([prob / total_visit_count for prob in action_probs])\n",
    "        return action_probs, root\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa952c",
   "metadata": {},
   "source": [
    "Test a Game using MCTS with Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "222ff2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game between self_play_agent and random_agent:\n",
      "Move number 1:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: 0\n",
      "Action played: (0, 2, 0, 1)\n",
      "\n",
      "Move number 2:\n",
      "State:\n",
      "[[ 0  2  0 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: 0.1\n",
      "Action played: (1, 2, 0, 1)\n",
      "\n",
      "Move number 3:\n",
      "State:\n",
      "[[ 0 -3  0 -1  0]\n",
      " [ 0  1  0  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: -0.1\n",
      "Action played: (1, 1, 2, 0)\n",
      "\n",
      "Move number 4:\n",
      "State:\n",
      "[[ 0 -3  0 -1  0]\n",
      " [ 0  0  0  1 -1]\n",
      " [ 2 -1  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: -0.1\n",
      "Action played: (3, 0, 2, 0)\n",
      "\n",
      "Move number 5:\n",
      "State:\n",
      "[[ 0 -3  0 -1  0]\n",
      " [ 0  0  0  1 -1]\n",
      " [-3 -1  1 -1  1]\n",
      " [ 0  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: -0.2\n",
      "Action played: (1, 3, 0, 3)\n",
      "\n",
      "Move number 6:\n",
      "State:\n",
      "[[ 0 -3  0  2  0]\n",
      " [ 0  0  0  0 -1]\n",
      " [-3 -1  1 -1  1]\n",
      " [ 0  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: -0.1\n",
      "Action played: (3, 1, 4, 2)\n",
      "\n",
      "Move number 7:\n",
      "State:\n",
      "[[ 0 -3  0  2  0]\n",
      " [ 0  0  0  0 -1]\n",
      " [-3 -1  1 -1  1]\n",
      " [ 0  0 -1  1  0]\n",
      " [ 1 -1  2 -1  0]]\n",
      "Score: -0.2\n",
      "Action played: (0, 3, 1, 4)\n",
      "\n",
      "Move number 8:\n",
      "State:\n",
      "[[ 0 -3  0  0  0]\n",
      " [ 0  0  0  0  3]\n",
      " [-3 -1  1 -1  1]\n",
      " [ 0  0 -1  1  0]\n",
      " [ 1 -1  2 -1  0]]\n",
      "Score: -0.1\n",
      "Action played: (4, 3, 4, 2)\n",
      "\n",
      "Move number 9:\n",
      "State:\n",
      "[[ 0 -3  0  0  0]\n",
      " [ 0  0  0  0  3]\n",
      " [-3 -1  1 -1  1]\n",
      " [ 0  0 -1  1  0]\n",
      " [ 1 -1 -3  0  0]]\n",
      "Score: -0.2\n",
      "Action played: (2, 2, 2, 1)\n",
      "\n",
      "Move number 10:\n",
      "State:\n",
      "[[ 0 -3  0  0  0]\n",
      " [ 0  0  0  0  3]\n",
      " [-3  2  0 -1  1]\n",
      " [ 0  0 -1  1  0]\n",
      " [ 1 -1 -3  0  0]]\n",
      "Score: -0.1\n",
      "Action played: (3, 2, 2, 1)\n",
      "\n",
      "Move number 11:\n",
      "State:\n",
      "[[ 0 -3  0  0  0]\n",
      " [ 0  0  0  0  3]\n",
      " [-3 -3  0 -1  1]\n",
      " [ 0  0  0  1  0]\n",
      " [ 1 -1 -3  0  0]]\n",
      "Score: -0.2\n",
      "Action played: (2, 4, 2, 3)\n",
      "\n",
      "Move number 12:\n",
      "State:\n",
      "[[ 0 -3  0  0  0]\n",
      " [ 0  0  0  0  3]\n",
      " [-3 -3  0  2  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 1 -1 -3  0  0]]\n",
      "Score: -0.1\n",
      "Action played: (4, 1, 4, 0)\n",
      "\n",
      "Move number 13:\n",
      "State:\n",
      "[[ 0 -3  0  0  0]\n",
      " [ 0  0  0  0  3]\n",
      " [-3 -3  0  2  0]\n",
      " [ 0  0  0  1  0]\n",
      " [-2  0 -3  0  0]]\n",
      "Score: -0.2\n",
      "Action played: (2, 3, 3, 3)\n",
      "\n",
      "Final state:\n",
      "[[ 0 -3  0  0  0]\n",
      " [ 0  0  0  0  3]\n",
      " [-3 -3  0  0  0]\n",
      " [ 0  0  0  3  0]\n",
      " [-2  0 -3  0  0]]\n",
      "Final score: -0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.3"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {\n",
    "    'C': 1.25,\n",
    "    'num_searches': 500,\n",
    "    'action_size': actions_size,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3, \n",
    "    'max_depth':100\n",
    "}\n",
    "mcts_supervised = MCTS_Supervised(args, device)\n",
    "agent_with_heuristics_args = {'model': None, 'mcts': mcts_supervised, 'args': args}\n",
    "\n",
    "\n",
    "\n",
    "print(\"Game between self_play_agent and random_agent:\")\n",
    "# play_game(self_play_agent, greedy_agent, agent1_args=agent_supervised_args)\n",
    "play_game(greedy_agent, self_play_agent, agent2_args=agent_with_heuristics_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a2bc0",
   "metadata": {},
   "source": [
    "#### 3.3 Self Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa265e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaZero_Supervised():\n",
    "    def __init__(self, model, optimizer, args):\n",
    "        self.model = model \n",
    "        self.optimizer = optimizer \n",
    "        self.args = args \n",
    "        self.mcts = MCTS_Supervised( args, device)\n",
    "    \n",
    "    def selfPlay(self):\n",
    "        memory = []\n",
    "        player = 1 \n",
    "        state = np.copy(initial_state) ## initialize game state \n",
    "\n",
    "        while True :       \n",
    "            action_probs, root = self.mcts.search(np.copy(state))\n",
    "            \n",
    "            memory.append((state, action_probs, player))\n",
    "            \n",
    "            temperature_action_probs = np.array(action_probs) ** (1/self.args[\"temperature\"])\n",
    "            temperature_action_probs /= np.sum(temperature_action_probs)\n",
    "            action_index = np.random.choice(actions_size, p=temperature_action_probs)  ## this action is scalar \n",
    "            action = index_to_action[action_index]\n",
    "            \n",
    "            ## get to next state using action \n",
    "            play_action_array(state,action) \n",
    "\n",
    "            value, is_terminal = get_score_array(state), is_finished_array(state)\n",
    "\n",
    "            if is_terminal : \n",
    "                returnMemory = []\n",
    "#                 for hist_neutral_state_encoded, hist_action_probs, hist_player in memory : \n",
    "                for hist_neutral_state, hist_action_probs, hist_player in memory : \n",
    "                    hist_outcome = value * hist_player \n",
    "#                     returnMemory.append((\n",
    "#                         get_encoded_state_(hist_neutral_state), \n",
    "#                         hist_action_probs, \n",
    "#                         hist_outcome\n",
    "#                     ))\n",
    "                    ### data augmentation \n",
    "                    combinations = generate_combinations(hist_neutral_state, hist_action_probs, hist_outcome)\n",
    "                    returnMemory.extend(combinations)\n",
    "                return returnMemory\n",
    "            \n",
    "            ## change perspective \n",
    "            state = -1 * np.array(state)\n",
    "            player *= -1\n",
    "            \n",
    "            \n",
    "\n",
    "    def train(self, memory):\n",
    "        random.shuffle(memory)\n",
    "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
    "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])]\n",
    "            state, policy_targets, value_targets = zip(*sample)\n",
    "            \n",
    "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
    "            \n",
    "            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n",
    "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
    "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
    "            \n",
    "            out_policy, out_value = self.model(state)\n",
    "            \n",
    "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
    "            value_loss = F.mse_loss(out_value, value_targets)\n",
    "            loss = policy_loss + value_loss\n",
    "            \n",
    "            optimizer.zero_grad() # change to self.optimizer\n",
    "            loss.backward()\n",
    "            optimizer.step() # change to self.optimizer\n",
    "            \n",
    "            \n",
    "\n",
    "    def learn(self):\n",
    "        \n",
    "        for iteration in range(self.args[\"num_iterations\"]):\n",
    "            memory = []\n",
    "\n",
    "            self.model.eval()\n",
    "            ## machine plays with itself \n",
    "            for selfPlay_iteration in trange(self.args[\"num_selfPlay_iterations\"]):\n",
    "                memory += self.selfPlay()\n",
    "\n",
    "            ## train based on the memory collected\n",
    "            self.model.train()\n",
    "            for epoch in trange(self.args[\"num_epochs\"]):\n",
    "                self.train(memory)\n",
    "                \n",
    "            iteration += self.args[\"start_iteration\"]\n",
    "            torch.save(self.model.state_dict(), f\"model_supervised_bigger_model_{iteration}.pt\" )\n",
    "            torch.save(self.optimizer.state_dict(), f\"optimizer_supervised_bigger_model_{iteration}.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3741a3ce",
   "metadata": {},
   "source": [
    "#### 3.4 Training with Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f04f948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.030999183654785156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a588aba2564956a65144308be82842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03691720962524414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8325edd87a1d48c38ad29ba6f7aed0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03587651252746582,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0149947bdb46049fcb1b6869ffc5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.024003982543945312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c96f98e7f947e6abed092fcd2b11fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022998332977294922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb6d1fa9ffd4b56aa90b5c418e2c613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03572416305541992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638563b0806941b6896eded50cf1cd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code took 557.65 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = ResNet( 3, 32, device=device, board_size = board_size, actions_size = actions_size)\n",
    "# model.load_state_dict(torch.load('model_1.pt', map_location=device))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "# optimizer.load_state_dict(torch.load('optimizer_1.pt', map_location=device))\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 300,\n",
    "    'num_iterations': 3,\n",
    "    'start_iteration': 10,\n",
    "    'num_selfPlay_iterations': 100,\n",
    "    'num_epochs': 5,\n",
    "    'batch_size': 64,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "#     'max_depth':100\n",
    "}\n",
    "\n",
    "alphaZero = AlphaZero_Supervised(model, optimizer, args)\n",
    "\n",
    "start_time = time.time()\n",
    "memory_ = alphaZero.learn()\n",
    "end_time = time.time()\n",
    "\n",
    "time_difference = end_time - start_time\n",
    "print(f'The code took {time_difference:.2f} seconds to run.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66902377",
   "metadata": {},
   "source": [
    "#### 3.5 Game between Supervised Self Play and Winner Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "083d9258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game between self_play_agent and random_agent:\n",
      "Move number 1:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: 0\n",
      "Action played: (4, 2, 4, 3)\n",
      "\n",
      "Move number 2:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  0  2  0]]\n",
      "Score: 0.1\n",
      "Action played: (3, 2, 4, 3)\n",
      "\n",
      "Move number 3:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1  0  1  0]\n",
      " [ 1 -1  0 -3  0]]\n",
      "Score: -0.1\n",
      "Action played: (3, 1, 4, 1)\n",
      "\n",
      "Move number 4:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  0  0  1  0]\n",
      " [ 1  2  0 -3  0]]\n",
      "Score: 0.1\n",
      "Action played: (3, 3, 2, 2)\n",
      "\n",
      "Move number 5:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  2 -1  1]\n",
      " [-1  0  0  0  0]\n",
      " [ 1  2  0 -3  0]]\n",
      "Score: -0.1\n",
      "Action played: (2, 2, 2, 1)\n",
      "\n",
      "Move number 6:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1  3  0 -1  1]\n",
      " [-1  0  0  0  0]\n",
      " [ 1  2  0 -3  0]]\n",
      "Score: 0.1\n",
      "Action played: (1, 4, 1, 3)\n",
      "\n",
      "Move number 7:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1 -2  0]\n",
      " [ 1  3  0 -1  1]\n",
      " [-1  0  0  0  0]\n",
      " [ 1  2  0 -3  0]]\n",
      "Score: 0\n",
      "Action played: (4, 1, 3, 0)\n",
      "\n",
      "Move number 8:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1 -2  0]\n",
      " [ 1  3  0 -1  1]\n",
      " [ 3  0  0  0  0]\n",
      " [ 1  0  0 -3  0]]\n",
      "Score: 0.1\n",
      "Action played: (1, 3, 2, 4)\n",
      "\n",
      "Move number 9:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  0  0]\n",
      " [ 1  3  0 -1 -3]\n",
      " [ 3  0  0  0  0]\n",
      " [ 1  0  0 -3  0]]\n",
      "Score: 0\n",
      "Action played: (1, 1, 0, 1)\n",
      "\n",
      "Move number 10:\n",
      "State:\n",
      "[[ 0  2  1 -1  0]\n",
      " [ 0  0 -1  0  0]\n",
      " [ 1  3  0 -1 -3]\n",
      " [ 3  0  0  0  0]\n",
      " [ 1  0  0 -3  0]]\n",
      "Score: 0.1\n",
      "Action played: (1, 2, 0, 1)\n",
      "\n",
      "Move number 11:\n",
      "State:\n",
      "[[ 0 -3  1 -1  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 1  3  0 -1 -3]\n",
      " [ 3  0  0  0  0]\n",
      " [ 1  0  0 -3  0]]\n",
      "Score: -0.1\n",
      "Action played: (0, 2, 0, 3)\n",
      "\n",
      "Final state:\n",
      "[[ 0 -3  0  2  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 1  3  0 -1 -3]\n",
      " [ 3  0  0  0  0]\n",
      " [ 1  0  0 -3  0]]\n",
      "Final score: 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet( 3, 32, device=device, board_size = board_size, actions_size = actions_size)\n",
    "model.load_state_dict(torch.load('model_supervised_2.pt', map_location=device))\n",
    "\n",
    "\n",
    "args = {\n",
    "    'C': 1.25,\n",
    "    'num_searches': 500,\n",
    "    'action_size': actions_size,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3, \n",
    "    'max_depth':100\n",
    "}\n",
    "mcts = MCTS(model,args, device)\n",
    "agent_supervised_args = {'model': model, 'mcts': mcts, 'args': args}\n",
    "\n",
    "\n",
    "\n",
    "print(\"Game between self_play_agent and random_agent:\")\n",
    "play_game(self_play_agent, self_play_agent, agent1_args=agent_supervised_args, agent2_args = agent_with_heuristics_args)\n",
    "# play_game(greedy_agent, self_play_agent, agent2_args=agent_supervised_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e476442f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def play_games(num_games, agent1, agent2, agent1_args=None, agent2_args=None):\n",
    "    agent1_wins = 0\n",
    "    agent2_wins = 0\n",
    "    draws = 0\n",
    "\n",
    "    for i in range(num_games):\n",
    "        if i % 2 == 0:\n",
    "            score = play_game(agent1, agent2, agent1_args, agent2_args, display=False)\n",
    "        else:\n",
    "            score = -play_game(agent2, agent1, agent2_args, agent1_args, display=False)\n",
    "\n",
    "        if score > 0:\n",
    "            agent1_wins += 1\n",
    "        elif score < 0:\n",
    "            agent2_wins += 1\n",
    "        else:\n",
    "            draws += 1\n",
    "\n",
    "    return agent1_wins, agent2_wins, draws\n",
    "\n",
    "\n",
    "num_games = 4\n",
    "\n",
    "self_play_vs_random = play_games(num_games, self_play_agent, random_agent, agent1_args=agent_supervised_args)\n",
    "self_play_vs_greedy = play_games(num_games, self_play_agent, greedy_agent, agent1_args=agent_supervised_args)\n",
    "self_play_vs_heuristics_agent = play_games(num_games, self_play_agent, self_play_agent, agent1_args=agent_supervised_args, agent2_args=agent_with_heuristics_args)\n",
    "\n",
    "\n",
    "# Plotting results\n",
    "x = np.arange(3)\n",
    "width = 0.3\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width, self_play_vs_random, width, label='Self Play with supervised vs Random')\n",
    "rects2 = ax.bar(x, self_play_vs_greedy, width, label='Self Play with supervised vs Greedy')\n",
    "rects3 = ax.bar(x + width, self_play_vs_heuristics_agent, width, label='Self Play with supervised vs Competition winner')\n",
    "\n",
    "ax.set_ylabel('Number of Games')\n",
    "ax.set_title('Self Play Agent Performance against Random, Greedy and Competition Winner Agents')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Wins', 'Losses', 'Draws'])\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95982f",
   "metadata": {},
   "source": [
    "#### Testing Supervised Self Play with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ac91ce57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game between self_play_agent and random_agent:\n",
      "Move number 1:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: 0\n",
      "Action played: (4, 2, 4, 3)\n",
      "\n",
      "Move number 2:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  0  2  0]]\n",
      "Score: 0.1\n",
      "Action played: (3, 2, 4, 3)\n",
      "\n",
      "Move number 3:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1  0  1  0]\n",
      " [ 1 -1  0 -3  0]]\n",
      "Score: -0.1\n",
      "Action played: (3, 1, 4, 1)\n",
      "\n",
      "Move number 4:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  0  0  1  0]\n",
      " [ 1  2  0 -3  0]]\n",
      "Score: 0.1\n",
      "Action played: (3, 0, 2, 0)\n",
      "\n",
      "Move number 5:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [-2 -1  1 -1  1]\n",
      " [ 0  0  0  1  0]\n",
      " [ 1  2  0 -3  0]]\n",
      "Score: -0.1\n",
      "Action played: (2, 4, 1, 4)\n",
      "\n",
      "Move number 6:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1  2]\n",
      " [-2 -1  1 -1  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 1  2  0 -3  0]]\n",
      "Score: 0.1\n",
      "Action played: (2, 1, 1, 1)\n",
      "\n",
      "Move number 7:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0 -2 -1  1  2]\n",
      " [-2  0  1 -1  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 1  2  0 -3  0]]\n",
      "Score: -0.1\n",
      "Action played: (1, 2, 1, 1)\n",
      "\n",
      "Move number 8:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0 -3  0  1  2]\n",
      " [-2  0  1 -1  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 1  2  0 -3  0]]\n",
      "Score: 0.1\n",
      "Action played: (2, 3, 1, 4)\n",
      "\n",
      "Move number 9:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0 -3  0  1 -3]\n",
      " [-2  0  1  0  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 1  2  0 -3  0]]\n",
      "Score: -0.3\n",
      "Action played: (4, 0, 4, 1)\n",
      "\n",
      "Move number 10:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0 -3  0  1 -3]\n",
      " [-2  0  1  0  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 0  3  0 -3  0]]\n",
      "Score: -0.1\n",
      "Action played: (1, 3, 2, 2)\n",
      "\n",
      "Move number 11:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0 -3  0  0 -3]\n",
      " [-2  0  2  0  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 0  3  0 -3  0]]\n",
      "Score: -0.2\n",
      "Action played: (0, 2, 0, 1)\n",
      "\n",
      "Move number 12:\n",
      "State:\n",
      "[[ 0  2  0 -1  0]\n",
      " [ 0 -3  0  0 -3]\n",
      " [-2  0  2  0  0]\n",
      " [ 0  0  0  1  0]\n",
      " [ 0  3  0 -3  0]]\n",
      "Score: -0.1\n",
      "Action played: (2, 2, 3, 3)\n",
      "\n",
      "Final state:\n",
      "[[ 0  2  0 -1  0]\n",
      " [ 0 -3  0  0 -3]\n",
      " [-2  0  0  0  0]\n",
      " [ 0  0  0  3  0]\n",
      " [ 0  3  0 -3  0]]\n",
      "Final score: -0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.2"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet( 3, 32, device=device, board_size = board_size, actions_size = actions_size)\n",
    "model.load_state_dict(torch.load('model_supervised_12.pt', map_location=device))\n",
    "\n",
    "\n",
    "args = {\n",
    "    'C': 1.25,\n",
    "    'num_searches': 500,\n",
    "    'action_size': actions_size,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3, \n",
    "    'max_depth':100\n",
    "}\n",
    "mcts = MCTS(model,args, device)\n",
    "agent_supervised_data_augm_args = {'model': model, 'mcts': mcts, 'args': args}\n",
    "\n",
    "\n",
    "\n",
    "print(\"Game between self_play_agent and random_agent:\")\n",
    "play_game(self_play_agent, self_play_agent, agent1_args=agent_supervised_data_augm_args, agent2_args = agent_supervised_args)\n",
    "# play_game(greedy_agent, self_play_agent, agent2_args=agent_supervised_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7e55a484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_games = 4\n",
    "\n",
    "self_play_vs_random = play_games(num_games, self_play_agent, random_agent, agent1_args=agent_supervised_data_augm_args)\n",
    "self_play_vs_greedy = play_games(num_games, self_play_agent, greedy_agent, agent1_args=agent_supervised_data_augm_args)\n",
    "self_play_vs_heuristics_agent = play_games(num_games, self_play_agent, self_play_agent, agent1_args=agent_supervised_data_augm_args, agent2_args=agent_with_heuristics_args)\n",
    "self_play_vs_supervised_wo_data_augmentation = play_games(num_games, self_play_agent, self_play_agent, agent1_args=agent_supervised_data_augm_args, agent2_args=agent_supervised_args)\n",
    "\n",
    "# Plotting results\n",
    "x = np.arange(3)\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rects1 = ax.bar(x - 3*width/2, self_play_vs_random, width, label='Data Augmentation vs Random')\n",
    "rects2 = ax.bar(x - width/2, self_play_vs_greedy, width, label='Data Augmentation vs Greedy')\n",
    "rects3 = ax.bar(x + width/2, self_play_vs_heuristics_agent, width, label='Data Augmentation vs Competition Winner')\n",
    "rects4 = ax.bar(x + 3*width/2, self_play_vs_supervised_wo_data_augmentation, width, label='Data Augmentation vs No Data Augmentation')\n",
    "\n",
    "ax.set_ylabel('Number of Games')\n",
    "ax.set_title('Self Play Agent with Supervised and Data Augmentation Performance')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Wins', 'Losses', 'Draws'])\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f790e7c",
   "metadata": {},
   "source": [
    "### Increase Model Architecture Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f8a39005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0299990177154541,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d0ee6b7c424a25ba6b589abb6a65c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.024000167846679688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5888f3e5b04a8185625a310a628b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.031000852584838867,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e27522be1bd409497736335703cfdf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.024891138076782227,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0052ddd39e43ce94e0587cc7cb33af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022005558013916016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 100,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944e87257901438091f911dc8f617ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0341954231262207,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 5,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e7fc1fc30d4a35aeb103161e056271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code took 545.53 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model = ResNet( 6, 64, device=device, board_size = board_size, actions_size = actions_size)\n",
    "# model.load_state_dict(torch.load('model_1.pt', map_location=device))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "# optimizer.load_state_dict(torch.load('optimizer_1.pt', map_location=device))\n",
    "\n",
    "args = {\n",
    "    'C': 2,\n",
    "    'num_searches': 300,\n",
    "    'num_iterations': 3,\n",
    "    'start_iteration': 10,\n",
    "    'num_selfPlay_iterations': 100,\n",
    "    'num_epochs': 5,\n",
    "    'batch_size': 64,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3\n",
    "#     'max_depth':100\n",
    "}\n",
    "\n",
    "alphaZero = AlphaZero_Supervised(model, optimizer, args)\n",
    "\n",
    "start_time = time.time()\n",
    "memory_ = alphaZero.learn()\n",
    "end_time = time.time()\n",
    "\n",
    "time_difference = end_time - start_time\n",
    "print(f'The code took {time_difference:.2f} seconds to run.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3d116ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game between self_play_agent and random_agent:\n",
      "Move number 1:\n",
      "State:\n",
      "[[ 0 -1  1 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: 0\n",
      "Action played: (0, 2, 0, 1)\n",
      "\n",
      "Move number 2:\n",
      "State:\n",
      "[[ 0  2  0 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 1 -1  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: 0.1\n",
      "Action played: (2, 0, 2, 1)\n",
      "\n",
      "Move number 3:\n",
      "State:\n",
      "[[ 0  2  0 -1  0]\n",
      " [ 0  1 -1  1 -1]\n",
      " [ 0  2  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: 0.2\n",
      "Action played: (0, 1, 1, 1)\n",
      "\n",
      "Move number 4:\n",
      "State:\n",
      "[[ 0  0  0 -1  0]\n",
      " [ 0  3 -1  1 -1]\n",
      " [ 0  2  1 -1  1]\n",
      " [-1  1 -1  1  0]\n",
      " [ 1 -1  1 -1  0]]\n",
      "Score: 0.1\n",
      "Action played: (3, 2, 4, 3)\n",
      "\n",
      "Move number 5:\n",
      "State:\n",
      "[[ 0  0  0 -1  0]\n",
      " [ 0  3 -1  1 -1]\n",
      " [ 0  2  1 -1  1]\n",
      " [-1  1  0  1  0]\n",
      " [ 1 -1  1 -2  0]]\n",
      "Score: 0.2\n",
      "Action played: (2, 1, 1, 2)\n",
      "\n",
      "Move number 6:\n",
      "State:\n",
      "[[ 0  0  0 -1  0]\n",
      " [ 0  3  3  1 -1]\n",
      " [ 0  0  1 -1  1]\n",
      " [-1  1  0  1  0]\n",
      " [ 1 -1  1 -2  0]]\n",
      "Score: 0.3\n",
      "Action played: (3, 3, 2, 2)\n",
      "\n",
      "Move number 7:\n",
      "State:\n",
      "[[ 0  0  0 -1  0]\n",
      " [ 0  3  3  1 -1]\n",
      " [ 0  0  2 -1  1]\n",
      " [-1  1  0  0  0]\n",
      " [ 1 -1  1 -2  0]]\n",
      "Score: 0.2\n",
      "Action played: (1, 3, 2, 2)\n",
      "\n",
      "Move number 8:\n",
      "State:\n",
      "[[ 0  0  0 -1  0]\n",
      " [ 0  3  3  0 -1]\n",
      " [ 0  0  3 -1  1]\n",
      " [-1  1  0  0  0]\n",
      " [ 1 -1  1 -2  0]]\n",
      "Score: 0.1\n",
      "Action played: (1, 4, 2, 4)\n",
      "\n",
      "Move number 9:\n",
      "State:\n",
      "[[ 0  0  0 -1  0]\n",
      " [ 0  3  3  0  0]\n",
      " [ 0  0  3 -1 -2]\n",
      " [-1  1  0  0  0]\n",
      " [ 1 -1  1 -2  0]]\n",
      "Score: 0.3\n",
      "Action played: (4, 2, 4, 3)\n",
      "\n",
      "Move number 10:\n",
      "State:\n",
      "[[ 0  0  0 -1  0]\n",
      " [ 0  3  3  0  0]\n",
      " [ 0  0  3 -1 -2]\n",
      " [-1  1  0  0  0]\n",
      " [ 1 -1  0  3  0]]\n",
      "Score: 0.1\n",
      "Action played: (4, 0, 3, 1)\n",
      "\n",
      "Move number 11:\n",
      "State:\n",
      "[[ 0  0  0 -1  0]\n",
      " [ 0  3  3  0  0]\n",
      " [ 0  0  3 -1 -2]\n",
      " [-1  2  0  0  0]\n",
      " [ 0 -1  0  3  0]]\n",
      "Score: 0.4\n",
      "Action played: (3, 1, 3, 0)\n",
      "\n",
      "Move number 12:\n",
      "State:\n",
      "[[ 0  0  0 -1  0]\n",
      " [ 0  3  3  0  0]\n",
      " [ 0  0  3 -1 -2]\n",
      " [ 3  0  0  0  0]\n",
      " [ 0 -1  0  3  0]]\n",
      "Score: 0.1\n",
      "Action played: (2, 4, 2, 3)\n",
      "\n",
      "Final state:\n",
      "[[ 0  0  0 -1  0]\n",
      " [ 0  3  3  0  0]\n",
      " [ 0  0  3 -3  0]\n",
      " [ 3  0  0  0  0]\n",
      " [ 0 -1  0  3  0]]\n",
      "Final score: 0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_big_model = ResNet( 6, 64, device=device, board_size = board_size, actions_size = actions_size)\n",
    "model_big_model.load_state_dict(torch.load('model_supervised_bigger_model_2.pt', map_location=device))\n",
    "\n",
    "\n",
    "args = {\n",
    "    'C': 1.25,\n",
    "    'num_searches': 500,\n",
    "    'action_size': actions_size,\n",
    "    'temperature': 1.25,\n",
    "    'dirichlet_epsilon': 0.25,\n",
    "    'dirichlet_alpha': 0.3, \n",
    "    'max_depth':100\n",
    "}\n",
    "mcts_big_model = MCTS(model_big_model,args, device)\n",
    "agent_supervised_bigger_model = {'model': model_big_model, 'mcts': mcts_big_model, 'args': args}\n",
    "\n",
    "## model with data augmentation\n",
    "model_big_model_dt_aug = ResNet( 6, 64, device=device, board_size = board_size, actions_size = actions_size)\n",
    "model_big_model_dt_aug.load_state_dict(torch.load('model_supervised_bigger_model_12.pt', map_location=device))\n",
    "\n",
    "mcts_big_model_dt_aug = MCTS(model_big_model_dt_aug,args, device)\n",
    "agent_supervised_bigger_model_dt_aug = {'model': model_big_model_dt_aug, 'mcts': mcts_big_model_dt_aug, 'args': args}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Game between self_play_agent and random_agent:\")\n",
    "play_game(greedy_agent, self_play_agent, agent1_args=None, agent2_args = agent_supervised_args)\n",
    "# play_game(greedy_agent, self_play_agent, agent2_args=agent_supervised_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6df9b045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_games = 4\n",
    "\n",
    "self_play_vs_random = play_games(num_games, self_play_agent, random_agent, agent1_args=agent_supervised_bigger_model)\n",
    "self_play_vs_greedy = play_games(num_games, self_play_agent, greedy_agent, agent1_args=agent_supervised_bigger_model)\n",
    "self_play_vs_heuristics_agent = play_games(num_games, self_play_agent, self_play_agent, agent1_args=agent_supervised_bigger_model, agent2_args=agent_with_heuristics_args)\n",
    "self_play_vs_supervised_wo_data_augmentation = play_games(num_games, self_play_agent, self_play_agent, agent1_args=agent_supervised_bigger_model, agent2_args=agent_supervised_args)\n",
    "\n",
    "# Plotting results\n",
    "x = np.arange(3)\n",
    "width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rects1 = ax.bar(x - 3*width/2, self_play_vs_random, width, label='Bigger Model vs Random')\n",
    "rects2 = ax.bar(x - width/2, self_play_vs_greedy, width, label='Bigger Model vs Greedy')\n",
    "rects3 = ax.bar(x + width/2, self_play_vs_heuristics_agent, width, label='Bigger Model vs Competition Winner')\n",
    "rects4 = ax.bar(x + 3*width/2, self_play_vs_supervised_wo_data_augmentation, width, label='Bigger Model vs Non Bigger Model')\n",
    "\n",
    "ax.set_ylabel('Number of Games')\n",
    "ax.set_title('Self Play Agent with Supervised and Data Augmentation Performance')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['Wins', 'Losses', 'Draws'])\n",
    "ax.legend()\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
